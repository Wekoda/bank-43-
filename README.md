# üí≥ Fraud-Detection-XGBoost: Modelo de Detec√ß√£o de Fraudes em Cart√µes de Cr√©dito

## üìÑ Descri√ß√£o do Projeto

Este projeto consiste no desenvolvimento e otimiza√ß√£o de um modelo de **Machine Learning** para a detec√ß√£o de **fraudes em transa√ß√µes de cart√£o de cr√©dito**. O principal desafio abordado foi o tratamento de uma base de dados extremamente **desbalanceada**, onde as transa√ß√µes fraudulentas (classe positiva) representam uma parcela √≠nfima do total.

O foco do projeto √© atingir um **alto Recall** (taxa de captura de fraudes) para minimizar a quantidade de fraudes perdidas (Falsos Negativos), mesmo que isso implique em uma taxa maior de Falsos Positivos (alertas falsos).

---

## üî¨ Metodologia e Abordagem

O notebook `entrega_bank_43.ipynb` documenta todo o processo, que incluiu:

### Pr√©-processamento e Base de Dados
* A base de dados utilizada j√° estava pr√©-processada, tendo sido aplicada a **An√°lise de Componentes Principais (PCA)** para anonimizar as vari√°veis, conforme o desafio de neg√≥cio.
* Dada a natureza do dataset, n√£o foi necess√°ria An√°lise Explorat√≥ria de Dados (EDA) ou visualiza√ß√£o gr√°fica pr√©via.
* A separa√ß√£o dos dados de treino e teste foi realizada de forma **estratificada** para garantir que a propor√ß√£o de fraudes fosse mantida em ambos os conjuntos.

### Modelagem e Otimiza√ß√£o
* Foi escolhido o algoritmo **XGBoost (Extreme Gradient Boosting)** para a modelagem devido √† sua efici√™ncia e robustez em bases de dados desbalanceadas.
* **Tratamento de Desbalanceamento:** Utilizou-se o hiperpar√¢metro `scale_pos_weight` no `XGBClassifier` para atribuir um peso elevado √† classe minorit√°ria (fraude). O valor calculado e aplicado foi de aproximadamente **577.29**, que representa a raz√£o entre a classe majorit√°ria e a minorit√°ria.
* **Ajuste Fino de Hiperpar√¢metros:** Ap√≥s uma avalia√ß√£o inicial, os hiperpar√¢metros do modelo foram ajustados para favorecer o desempenho:
    * `learning_rate`: reduzido para **0.01**.
    * `max_depth`: reduzido para **3**.
    * `n_estimators`: definido como **200**.
* **Otimiza√ß√£o do Threshold:** O **threshold de decis√£o** do modelo foi otimizado de 0.5 para **0.3**, com base na Curva Precision-Recall, para aumentar ainda mais a sensibilidade (Recall) do modelo na detec√ß√£o de fraudes.

---

## üõ†Ô∏è Tecnologias e Depend√™ncias

O projeto foi desenvolvido em **Python** no ambiente Jupyter Notebook e requer as seguintes bibliotecas:

* `pandas`
* `numpy`
* `scikit-learn` (para divis√£o, m√©tricas e curva Precision-Recall)
* `xgboost` (`XGBClassifier`)
* `matplotlib` (para visualiza√ß√£o da curva)

---

## üìä Resultados Chave do Modelo Final

O modelo final, utilizando o **Threshold de Compromisso (0.3)** e a otimiza√ß√£o dos hiperpar√¢metros, atingiu o objetivo de neg√≥cio com as seguintes m√©tricas de desempenho no conjunto de teste:

| M√©trica | Valor | Objetivo de Neg√≥cio |
| :--- | :--- | :--- |
| **Recall (Captura de Fraudes)** | **0.9286** (92,86%) | **Prioridade M√°xima:** Garantir que o m√≠nimo de fraudes seja perdido (Falsos Negativos). |
| **Precision (Acur√°cia das Previs√µes)** | 0.0258 (2,58%) | Aceit√°vel, pois o custo de um Falso Positivo (alerta falso) √© menor que o custo de uma Fraude Perdida (Falso Negativo). |
| **AUC-ROC** | *Alta* | Indica excelente separabilidade geral das classes. |

### Matriz de Confus√£o (Threshold 0.3)

| Previs√£o | N√£o-Fraude (0) | Fraude (1) |
| :--- | :--- | :--- |
| **Real N√£o-Fraude (0)** | 53424 (Verdadeiros Negativos) | 3440 (Falsos Positivos) |
| **Real Fraude (1)** | **7** (Falsos Negativos) | 91 (Verdadeiros Positivos) |

**Conclus√£o:** O modelo demonstrou alta efic√°cia, resultando em apenas **7 fraudes perdidas (Falsos Negativos)** no conjunto de teste, garantindo um Recall de 92,86%. A estrat√©gia de ajustar o threshold e o peso de classe foi crucial para este resultado.

---
